{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import trange,tqdm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from sklearnex import patch_sklearn, config_context\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, RandomizedSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('weather_training.csv')\n",
    "df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>province</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>wind</th>\n",
       "      <th>wind_d</th>\n",
       "      <th>rain</th>\n",
       "      <th>humidi</th>\n",
       "      <th>cloud</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-01-01</th>\n",
       "      <td>Bac Lieu</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>NNE</td>\n",
       "      <td>6.9</td>\n",
       "      <td>90</td>\n",
       "      <td>71</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>Bac Lieu</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>ENE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64</td>\n",
       "      <td>24</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "      <td>Bac Lieu</td>\n",
       "      <td>29</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>E</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>45</td>\n",
       "      <td>1008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01</th>\n",
       "      <td>Bac Lieu</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>E</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79</td>\n",
       "      <td>52</td>\n",
       "      <td>1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>Bac Lieu</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>ENE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70</td>\n",
       "      <td>24</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            province  max  min  wind wind_d  rain  humidi  cloud  pressure\n",
       "date                                                                      \n",
       "2009-01-01  Bac Lieu   27   22    17    NNE   6.9      90     71      1010\n",
       "2010-01-01  Bac Lieu   31   25    20    ENE   0.0      64     24      1010\n",
       "2011-01-01  Bac Lieu   29   24    14      E   0.0      75     45      1008\n",
       "2012-01-01  Bac Lieu   30   24    30      E   0.0      79     52      1012\n",
       "2013-01-01  Bac Lieu   31   25    20    ENE   0.0      70     24      1010"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = ['max', 'min', 'wind' ,'humidi', 'cloud', 'pressure']\n",
    "cat = ['province','wind_d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>province</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>wind</th>\n",
       "      <th>wind_d</th>\n",
       "      <th>humidi</th>\n",
       "      <th>cloud</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-01-01</th>\n",
       "      <td>Bac Lieu</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>NNE</td>\n",
       "      <td>90</td>\n",
       "      <td>71</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>Bac Lieu</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>ENE</td>\n",
       "      <td>64</td>\n",
       "      <td>24</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "      <td>Bac Lieu</td>\n",
       "      <td>29</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>E</td>\n",
       "      <td>75</td>\n",
       "      <td>45</td>\n",
       "      <td>1008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01</th>\n",
       "      <td>Bac Lieu</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>E</td>\n",
       "      <td>79</td>\n",
       "      <td>52</td>\n",
       "      <td>1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>Bac Lieu</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>ENE</td>\n",
       "      <td>70</td>\n",
       "      <td>24</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-28</th>\n",
       "      <td>Soc Trang</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>SSW</td>\n",
       "      <td>75</td>\n",
       "      <td>50</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-28</th>\n",
       "      <td>Soc Trang</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>ENE</td>\n",
       "      <td>81</td>\n",
       "      <td>50</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-28</th>\n",
       "      <td>Soc Trang</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>ENE</td>\n",
       "      <td>91</td>\n",
       "      <td>75</td>\n",
       "      <td>1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28</th>\n",
       "      <td>Soc Trang</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>E</td>\n",
       "      <td>74</td>\n",
       "      <td>6</td>\n",
       "      <td>1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-28</th>\n",
       "      <td>Soc Trang</td>\n",
       "      <td>29</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>ESE</td>\n",
       "      <td>84</td>\n",
       "      <td>43</td>\n",
       "      <td>1009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181960 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             province  max  min  wind wind_d  humidi  cloud  pressure\n",
       "date                                                                 \n",
       "2009-01-01   Bac Lieu   27   22    17    NNE      90     71      1010\n",
       "2010-01-01   Bac Lieu   31   25    20    ENE      64     24      1010\n",
       "2011-01-01   Bac Lieu   29   24    14      E      75     45      1008\n",
       "2012-01-01   Bac Lieu   30   24    30      E      79     52      1012\n",
       "2013-01-01   Bac Lieu   31   25    20    ENE      70     24      1010\n",
       "...               ...  ...  ...   ...    ...     ...    ...       ...\n",
       "2016-12-28  Soc Trang   28   23     8    SSW      75     50      1011\n",
       "2017-12-28  Soc Trang   30   24    21    ENE      81     50      1011\n",
       "2018-12-28  Soc Trang   26   24     9    ENE      91     75      1009\n",
       "2019-12-28  Soc Trang   30   23    11      E      74      6      1012\n",
       "2020-12-28  Soc Trang   29   24     9    ESE      84     43      1009\n",
       "\n",
       "[181960 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['rain'], axis=1)\n",
    "y = df['rain'].astype('str')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2009-01-01    6.9\n",
       "2010-01-01    0.0\n",
       "2011-01-01    0.0\n",
       "2012-01-01    0.0\n",
       "2013-01-01    0.0\n",
       "             ... \n",
       "2016-12-28    0.0\n",
       "2017-12-28    7.2\n",
       "2018-12-28    1.3\n",
       "2019-12-28    0.0\n",
       "2020-12-28    0.7\n",
       "Name: rain, Length: 181960, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(y)):\n",
    "    if y[index] != '0.0':\n",
    "        y[index] = 'Rain'\n",
    "    else:\n",
    "        y[index] = 'No Rain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>province</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>wind</th>\n",
       "      <th>wind_d</th>\n",
       "      <th>humidi</th>\n",
       "      <th>cloud</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-01-01</th>\n",
       "      <td>0</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.301887</td>\n",
       "      <td>5</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>0</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.358491</td>\n",
       "      <td>1</td>\n",
       "      <td>0.532468</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "      <td>0</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01</th>\n",
       "      <td>0</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.547170</td>\n",
       "      <td>0</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.358491</td>\n",
       "      <td>1</td>\n",
       "      <td>0.610390</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            province       max       min      wind  wind_d    humidi  cloud  \\\n",
       "date                                                                          \n",
       "2009-01-01         0  0.547619  0.666667  0.301887       5  0.870130   0.71   \n",
       "2010-01-01         0  0.642857  0.766667  0.358491       1  0.532468   0.24   \n",
       "2011-01-01         0  0.595238  0.733333  0.245283       0  0.675325   0.45   \n",
       "2012-01-01         0  0.619048  0.733333  0.547170       0  0.727273   0.52   \n",
       "2013-01-01         0  0.642857  0.766667  0.358491       1  0.610390   0.24   \n",
       "\n",
       "            pressure  \n",
       "date                  \n",
       "2009-01-01      0.44  \n",
       "2010-01-01      0.44  \n",
       "2011-01-01      0.40  \n",
       "2012-01-01      0.48  \n",
       "2013-01-01      0.44  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "X[num] = min_max_scaler.fit_transform(X[num])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for column in cat:\n",
    "    X[column] = label_encoder.fit_transform(X[column])\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = label_encoder.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>province</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>wind</th>\n",
       "      <th>wind_d</th>\n",
       "      <th>humidi</th>\n",
       "      <th>cloud</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-01-01</th>\n",
       "      <td>0</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.301887</td>\n",
       "      <td>5</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>0</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.358491</td>\n",
       "      <td>1</td>\n",
       "      <td>0.532468</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "      <td>0</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01</th>\n",
       "      <td>0</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.547170</td>\n",
       "      <td>0</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.358491</td>\n",
       "      <td>1</td>\n",
       "      <td>0.610390</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-28</th>\n",
       "      <td>27</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.132075</td>\n",
       "      <td>11</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-28</th>\n",
       "      <td>27</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.377358</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-28</th>\n",
       "      <td>27</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>1</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28</th>\n",
       "      <td>27</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.188679</td>\n",
       "      <td>0</td>\n",
       "      <td>0.662338</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-28</th>\n",
       "      <td>27</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>2</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181960 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            province       max       min      wind  wind_d    humidi  cloud  \\\n",
       "date                                                                          \n",
       "2009-01-01         0  0.547619  0.666667  0.301887       5  0.870130   0.71   \n",
       "2010-01-01         0  0.642857  0.766667  0.358491       1  0.532468   0.24   \n",
       "2011-01-01         0  0.595238  0.733333  0.245283       0  0.675325   0.45   \n",
       "2012-01-01         0  0.619048  0.733333  0.547170       0  0.727273   0.52   \n",
       "2013-01-01         0  0.642857  0.766667  0.358491       1  0.610390   0.24   \n",
       "...              ...       ...       ...       ...     ...       ...    ...   \n",
       "2016-12-28        27  0.571429  0.700000  0.132075      11  0.675325   0.50   \n",
       "2017-12-28        27  0.619048  0.733333  0.377358       1  0.753247   0.50   \n",
       "2018-12-28        27  0.523810  0.733333  0.150943       1  0.883117   0.75   \n",
       "2019-12-28        27  0.619048  0.700000  0.188679       0  0.662338   0.06   \n",
       "2020-12-28        27  0.595238  0.733333  0.150943       2  0.792208   0.43   \n",
       "\n",
       "            pressure  \n",
       "date                  \n",
       "2009-01-01      0.44  \n",
       "2010-01-01      0.44  \n",
       "2011-01-01      0.40  \n",
       "2012-01-01      0.48  \n",
       "2013-01-01      0.44  \n",
       "...              ...  \n",
       "2016-12-28      0.46  \n",
       "2017-12-28      0.46  \n",
       "2018-12-28      0.42  \n",
       "2019-12-28      0.48  \n",
       "2020-12-28      0.42  \n",
       "\n",
       "[181960 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (181960, 8)\n",
      "Shape of y: (181960, 1)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "y = y.reshape(-1,1)\n",
    "X = X.astype('float32')\n",
    "y = y.astype('float32')\n",
    "\n",
    "print(\"Shape of X: {}\".format(X.shape))\n",
    "print(\"Shape of y: {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (127372, 8)\n",
      "Shape of y_train: (127372, 1)\n",
      "Shape of X_test: (54588, 8)\n",
      "Shape of y_test: (54588, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=SEED)\n",
    "\n",
    "print(\"Shape of X_train: {}\".format(X_train.shape))\n",
    "print(\"Shape of y_train: {}\".format(Y_train.shape))\n",
    "print(\"Shape of X_test: {}\".format(X_test.shape))\n",
    "print(\"Shape of y_test: {}\".format(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [100, 200, 500, 1000, 2000], 'max_features': ['sqrt', 'log2', None], 'max_depth': [2, 5, 8, 10, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False], 'criterion': ['gini', 'entropy', 'log_loss']}\n",
      "{'n_estimators': [50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 120, 125], 'max_features': [50, 100, 150, 200, 250, 300, 350, 400], 'min_samples_leaf': [20, 25, 30, 35, 40, 45, 50], 'min_samples_split': [15, 20, 25, 30, 35]}\n",
      "{'min_child_weight': [1, 5, 10], 'gamma': [0.5, 1, 1.5, 2, 5], 'subsample': [0.6, 0.8, 1.0], 'colsample_bytree': [0.6, 0.8, 1.0], 'max_depth': [3, 4, 5]}\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [100, 200, 500, 1000, 2000] # [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)] # Nhiều quá ->\n",
    "max_features = ['sqrt', 'log2', None] #Trong bai cua co la 2, 4, 5 ,9, 10, 15, 18\n",
    "min_samples_split = [2, 5, 10] # Trong bai la 5, 11 #Nên lấy số lẻ\n",
    "\n",
    "max_depth = [2, 5, 8, 10, None]\n",
    "# [int(x) for x in np.linspace(5, 110, num = 22)] #-> 2, 5, 8, 10, None\n",
    "# max_depth.append(None)\n",
    "criterion = ['gini', 'entropy', 'log_loss']\n",
    "\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "bootstrap = [True, False]\n",
    "\n",
    "\n",
    "Random_forest_search = {'n_estimators': n_estimators,\n",
    "                       'max_features': max_features,\n",
    "                       'max_depth': max_depth,\n",
    "                       'min_samples_split': min_samples_split,\n",
    "                       'min_samples_leaf': min_samples_leaf,\n",
    "                       'bootstrap': bootstrap,\n",
    "                       'criterion': criterion}\n",
    "print(Random_forest_search)\n",
    "\n",
    "Extra_trees_search={'n_estimators': [int(x) for x in np.arange(50, 126, 5)],\n",
    "                    'max_features': [int(x) for x in np.arange(50, 401, 50)],\n",
    "                    'min_samples_leaf':  [int(x) for x in np.arange(20, 51, 5)],\n",
    "                    'min_samples_split': [int(x) for x in np.arange(15, 36, 5)],\n",
    "                    }\n",
    "print(Extra_trees_search)\n",
    "\n",
    "XGBoost_search = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }\n",
    "print(XGBoost_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [['ExtraTreesClassifier', ExtraTreesClassifier(random_state=SEED), Extra_trees_search],\n",
    "              ['RandomForestClassifier', RandomForestClassifier(random_state=SEED), Random_forest_search],\n",
    "                ['XGBClassifier', XGBClassifier(random_state=SEED), XGBoost_search]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_best_models(model, parameter_search, scoring='accuracy', verbose=5):\n",
    "    search = RandomizedSearchCV(model, parameter_search, n_iter=10, scoring=scoring, verbose = verbose, n_jobs=1, cv=None, random_state=SEED)\n",
    "    search.fit(X_train, Y_train) \n",
    "    best_model = search.best_estimator_\n",
    "    optimal_params = search.best_params_\n",
    "    Y_pred = best_model.predict(X_test)\n",
    "    accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "    print(\"Model: {}\".format(model.__class__.__name__))\n",
    "    print(\"Best parameters: {}\".format(search.best_params_))\n",
    "    print(\"Best cross-validation score: {:.2f}\".format(search.best_score_))\n",
    "    print(\"Test set score: {:.2f}\".format(accuracy))\n",
    "    print(\"-\"*50)\n",
    "\n",
    "    return best_model, search, accuracy, optimal_params\n",
    "\n",
    "def plot_roc_curve(Y_test, Y_pred, name, title):\n",
    "    fpr, tpr, thresholds = roc_curve(Y_test, Y_pred)\n",
    "\n",
    "    auc = roc_auc_score(Y_test, Y_pred)\n",
    "\n",
    "    plt.plot(fpr, tpr, label=\"{0} (a = {1:.2f})\".format(name.replace(\"Classifier\", \"\"), auc))\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"dashed\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"ML__RandomSearchCV_ROC_Curve.png\")\n",
    "    # plt.show()\n",
    "\n",
    "def plot_confusion_matrix(cm, title):\n",
    "    df_cm = pd.DataFrame(cm, index = [i for i in ['Queen', 'Queenless']],\n",
    "                    columns = [i for i in ['Queen', 'Queenless']])\n",
    "    df_cm_normed = df_cm/df_cm.sum()\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sns.heatmap(df_cm, annot=True, fmt=\"\", )\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17.          0.5         0.53333336  0.1509434   9.          0.74025977\n",
      "   0.2         0.62      ]\n",
      " [26.          0.64285713  0.8333333   0.18867925  9.          0.6883117\n",
      "   0.49        0.44      ]\n",
      " [15.          0.6904762   0.6333333   0.0754717   9.          0.64935064\n",
      "   0.55        0.4       ]\n",
      " [19.          0.71428573  0.76666665  0.24528302  2.          0.53246754\n",
      "   0.14        0.46      ]\n",
      " [20.          0.5         0.56666666  0.13207547  0.          0.7532467\n",
      "   0.65        0.56      ]]\n"
     ]
    }
   ],
   "source": [
    "# global cv\n",
    "# cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=2, random_state=SEED)\n",
    "# global X_train, Y_train, X_test, Y_test\n",
    "# print(X_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "global X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "patch_sklearn()\n",
    "\n",
    "def evaluate_classifiers(classifiers):\n",
    "    models = []\n",
    "    Accuracy_set = pd.DataFrame(index=None, columns=['Model','Accuracy(Train)','Accuracy(Test)','F1(Train)','F1(Test)', 'Precision(Train)','Precision(Test)', 'Recall(Train)','Recall(Test)', 'Log_loss(Train)','Log_loss(Test)', 'Train_Time(s)', 'Confusion_Matrix(Test)', 'Optimal_Params'])\n",
    "    for i in tqdm(range(len(classifiers))):\n",
    "        name = classifiers[i][0]\n",
    "        model = classifiers[i][1]\n",
    "        params = classifiers[i][2]\n",
    "        time_start = time.time()\n",
    "        best_model, search, accuracy, optimal_params = search_for_best_models(model, params)\n",
    "        time_end = time.time()\n",
    "\n",
    "        Y_train_predicted = best_model.predict(X_train)\n",
    "        Y_test_predicited = best_model.predict(X_test)\n",
    "        \n",
    "        plot_roc_curve(Y_test, Y_test_predicited, name, \"Machine Learning Algorithms Roc-Curve\")\n",
    "\n",
    "        accuracy_train = accuracy_score(Y_train, Y_train_predicted)\n",
    "        accuracy_test = accuracy_score(Y_test, Y_test_predicited)\n",
    "\n",
    "        f1_Score_train = f1_score(Y_train, Y_train_predicted,average='micro')\n",
    "        f1_Score_test = f1_score(Y_test, Y_test_predicited,average='micro')\n",
    "\n",
    "        precision_score_train = precision_score(Y_train, Y_train_predicted,average='micro')\n",
    "        precision_score_test = precision_score(Y_test, Y_test_predicited,average='micro')\n",
    "\n",
    "        recall_score_train = recall_score(Y_train, Y_train_predicted,average='micro')\n",
    "        recall_score_test = recall_score(Y_test, Y_test_predicited,average='micro')\n",
    "\n",
    "        log_loss_train = log_loss(Y_train, best_model.predict_proba(X_train))\n",
    "        log_loss_test = log_loss(Y_test, best_model.predict_proba(X_test))\n",
    "        \n",
    "        cf_matrix = confusion_matrix(Y_test, Y_test_predicited)\n",
    "\n",
    "        train_time = time_end - time_start\n",
    "        \n",
    "        # store the models\n",
    "        models.append((name,accuracy_test,best_model))\n",
    "\n",
    "        Accuracy_set = Accuracy_set.append(pd.Series({'Model':name, 'Accuracy(Train)':accuracy_train,'Accuracy(Test)':accuracy_test,'F1(Train)':f1_Score_train,'F1(Test)':f1_Score_test,'Precision(Train)':precision_score_train,'Precision(Test)':precision_score_test,'Recall(Train)':recall_score_train,'Recall(Test)':recall_score_test,'Log_loss(Train)':log_loss_train,'Log_loss(Test)':log_loss_test,'Train_Time(s)':train_time, 'Confusion_Matrix(Test)':cf_matrix, 'Optimal_Params':optimal_params}),ignore_index=True)\n",
    "        time.sleep(0.1)\n",
    "    return Accuracy_set, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b979e24bbe184884b4435133aa072670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END max_features=300, min_samples_leaf=45, min_samples_split=20, n_estimators=85;, score=0.893 total time=   9.9s\n",
      "[CV 2/5] END max_features=300, min_samples_leaf=45, min_samples_split=20, n_estimators=85;, score=0.889 total time=  10.4s\n",
      "[CV 3/5] END max_features=300, min_samples_leaf=45, min_samples_split=20, n_estimators=85;, score=0.891 total time=   9.0s\n",
      "[CV 4/5] END max_features=300, min_samples_leaf=45, min_samples_split=20, n_estimators=85;, score=0.890 total time=   8.1s\n",
      "[CV 5/5] END max_features=300, min_samples_leaf=45, min_samples_split=20, n_estimators=85;, score=0.889 total time=   7.8s\n",
      "[CV 1/5] END max_features=50, min_samples_leaf=30, min_samples_split=20, n_estimators=115;, score=0.894 total time=  11.0s\n",
      "[CV 2/5] END max_features=50, min_samples_leaf=30, min_samples_split=20, n_estimators=115;, score=0.892 total time=  11.1s\n",
      "[CV 3/5] END max_features=50, min_samples_leaf=30, min_samples_split=20, n_estimators=115;, score=0.894 total time=  11.7s\n",
      "[CV 4/5] END max_features=50, min_samples_leaf=30, min_samples_split=20, n_estimators=115;, score=0.892 total time=  17.3s\n",
      "[CV 5/5] END max_features=50, min_samples_leaf=30, min_samples_split=20, n_estimators=115;, score=0.891 total time=  12.5s\n",
      "[CV 1/5] END max_features=100, min_samples_leaf=35, min_samples_split=30, n_estimators=110;, score=0.894 total time=  11.6s\n",
      "[CV 2/5] END max_features=100, min_samples_leaf=35, min_samples_split=30, n_estimators=110;, score=0.890 total time=  11.5s\n",
      "[CV 3/5] END max_features=100, min_samples_leaf=35, min_samples_split=30, n_estimators=110;, score=0.893 total time=  11.7s\n",
      "[CV 4/5] END max_features=100, min_samples_leaf=35, min_samples_split=30, n_estimators=110;, score=0.892 total time=  11.7s\n",
      "[CV 5/5] END max_features=100, min_samples_leaf=35, min_samples_split=30, n_estimators=110;, score=0.891 total time=  11.7s\n",
      "[CV 1/5] END max_features=150, min_samples_leaf=25, min_samples_split=30, n_estimators=90;, score=0.895 total time=   9.8s\n",
      "[CV 2/5] END max_features=150, min_samples_leaf=25, min_samples_split=30, n_estimators=90;, score=0.892 total time=  10.6s\n",
      "[CV 3/5] END max_features=150, min_samples_leaf=25, min_samples_split=30, n_estimators=90;, score=0.895 total time=   9.9s\n",
      "[CV 4/5] END max_features=150, min_samples_leaf=25, min_samples_split=30, n_estimators=90;, score=0.893 total time=   9.7s\n",
      "[CV 5/5] END max_features=150, min_samples_leaf=25, min_samples_split=30, n_estimators=90;, score=0.891 total time=   9.8s\n",
      "[CV 1/5] END max_features=300, min_samples_leaf=45, min_samples_split=25, n_estimators=85;, score=0.893 total time=   9.0s\n",
      "[CV 2/5] END max_features=300, min_samples_leaf=45, min_samples_split=25, n_estimators=85;, score=0.889 total time=   8.9s\n",
      "[CV 3/5] END max_features=300, min_samples_leaf=45, min_samples_split=25, n_estimators=85;, score=0.891 total time=   8.5s\n",
      "[CV 4/5] END max_features=300, min_samples_leaf=45, min_samples_split=25, n_estimators=85;, score=0.890 total time=   8.5s\n",
      "[CV 5/5] END max_features=300, min_samples_leaf=45, min_samples_split=25, n_estimators=85;, score=0.889 total time=   8.5s\n",
      "[CV 1/5] END max_features=250, min_samples_leaf=50, min_samples_split=15, n_estimators=85;, score=0.893 total time=   8.2s\n",
      "[CV 2/5] END max_features=250, min_samples_leaf=50, min_samples_split=15, n_estimators=85;, score=0.888 total time=   8.4s\n",
      "[CV 3/5] END max_features=250, min_samples_leaf=50, min_samples_split=15, n_estimators=85;, score=0.891 total time=   8.2s\n",
      "[CV 4/5] END max_features=250, min_samples_leaf=50, min_samples_split=15, n_estimators=85;, score=0.890 total time=   8.3s\n",
      "[CV 5/5] END max_features=250, min_samples_leaf=50, min_samples_split=15, n_estimators=85;, score=0.889 total time=   8.1s\n",
      "[CV 1/5] END max_features=400, min_samples_leaf=35, min_samples_split=20, n_estimators=60;, score=0.894 total time=   6.2s\n",
      "[CV 2/5] END max_features=400, min_samples_leaf=35, min_samples_split=20, n_estimators=60;, score=0.890 total time=   6.0s\n",
      "[CV 3/5] END max_features=400, min_samples_leaf=35, min_samples_split=20, n_estimators=60;, score=0.893 total time=   6.2s\n",
      "[CV 4/5] END max_features=400, min_samples_leaf=35, min_samples_split=20, n_estimators=60;, score=0.892 total time=   6.1s\n",
      "[CV 5/5] END max_features=400, min_samples_leaf=35, min_samples_split=20, n_estimators=60;, score=0.890 total time=   6.2s\n",
      "[CV 1/5] END max_features=100, min_samples_leaf=50, min_samples_split=35, n_estimators=70;, score=0.894 total time=   7.6s\n",
      "[CV 2/5] END max_features=100, min_samples_leaf=50, min_samples_split=35, n_estimators=70;, score=0.889 total time=   8.0s\n",
      "[CV 3/5] END max_features=100, min_samples_leaf=50, min_samples_split=35, n_estimators=70;, score=0.891 total time=   7.4s\n",
      "[CV 4/5] END max_features=100, min_samples_leaf=50, min_samples_split=35, n_estimators=70;, score=0.890 total time=   7.3s\n",
      "[CV 5/5] END max_features=100, min_samples_leaf=50, min_samples_split=35, n_estimators=70;, score=0.889 total time=   7.5s\n",
      "[CV 1/5] END max_features=400, min_samples_leaf=45, min_samples_split=25, n_estimators=95;, score=0.893 total time=   9.9s\n",
      "[CV 2/5] END max_features=400, min_samples_leaf=45, min_samples_split=25, n_estimators=95;, score=0.888 total time=   9.9s\n",
      "[CV 3/5] END max_features=400, min_samples_leaf=45, min_samples_split=25, n_estimators=95;, score=0.891 total time=  10.3s\n",
      "[CV 4/5] END max_features=400, min_samples_leaf=45, min_samples_split=25, n_estimators=95;, score=0.890 total time=   9.7s\n",
      "[CV 5/5] END max_features=400, min_samples_leaf=45, min_samples_split=25, n_estimators=95;, score=0.889 total time=  10.0s\n",
      "[CV 1/5] END max_features=350, min_samples_leaf=20, min_samples_split=30, n_estimators=100;, score=0.896 total time=  11.1s\n",
      "[CV 2/5] END max_features=350, min_samples_leaf=20, min_samples_split=30, n_estimators=100;, score=0.893 total time=  12.0s\n",
      "[CV 3/5] END max_features=350, min_samples_leaf=20, min_samples_split=30, n_estimators=100;, score=0.895 total time=  11.4s\n",
      "[CV 4/5] END max_features=350, min_samples_leaf=20, min_samples_split=30, n_estimators=100;, score=0.894 total time=  11.3s\n",
      "[CV 5/5] END max_features=350, min_samples_leaf=20, min_samples_split=30, n_estimators=100;, score=0.893 total time=  11.1s\n",
      "Model: ExtraTreesClassifier\n",
      "Best parameters: {'n_estimators': 100, 'min_samples_split': 30, 'min_samples_leaf': 20, 'max_features': 350}\n",
      "Best cross-validation score: 0.89\n",
      "Test set score: 0.90\n",
      "--------------------------------------------------\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END bootstrap=False, criterion=entropy, max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=10, n_estimators=1000;, score=0.888 total time= 4.8min\n",
      "[CV 2/5] END bootstrap=False, criterion=entropy, max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=10, n_estimators=1000;, score=0.882 total time= 4.6min\n",
      "[CV 3/5] END bootstrap=False, criterion=entropy, max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=10, n_estimators=1000;, score=0.885 total time= 4.5min\n",
      "[CV 4/5] END bootstrap=False, criterion=entropy, max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=10, n_estimators=1000;, score=0.888 total time= 4.7min\n",
      "[CV 5/5] END bootstrap=False, criterion=entropy, max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=10, n_estimators=1000;, score=0.884 total time= 4.4min\n",
      "[CV 1/5] END bootstrap=True, criterion=gini, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=0.878 total time= 1.6min\n",
      "[CV 2/5] END bootstrap=True, criterion=gini, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=0.875 total time= 1.6min\n",
      "[CV 3/5] END bootstrap=True, criterion=gini, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=0.879 total time= 1.7min\n",
      "[CV 4/5] END bootstrap=True, criterion=gini, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=0.880 total time= 1.7min\n",
      "[CV 5/5] END bootstrap=True, criterion=gini, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=0.876 total time= 1.7min\n",
      "[CV 1/5] END bootstrap=True, criterion=entropy, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.880 total time=   5.1s\n",
      "[CV 2/5] END bootstrap=True, criterion=entropy, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.874 total time=   5.0s\n",
      "[CV 3/5] END bootstrap=True, criterion=entropy, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.879 total time=   5.0s\n",
      "[CV 4/5] END bootstrap=True, criterion=entropy, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.880 total time=   4.9s\n",
      "[CV 5/5] END bootstrap=True, criterion=entropy, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.877 total time=   4.9s\n",
      "[CV 1/5] END bootstrap=True, criterion=entropy, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.904 total time=  17.7s\n",
      "[CV 2/5] END bootstrap=True, criterion=entropy, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.901 total time=  17.4s\n",
      "[CV 3/5] END bootstrap=True, criterion=entropy, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.904 total time=  17.3s\n",
      "[CV 4/5] END bootstrap=True, criterion=entropy, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.904 total time=  17.5s\n",
      "[CV 5/5] END bootstrap=True, criterion=entropy, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.901 total time=  17.7s\n",
      "[CV 1/5] END bootstrap=False, criterion=entropy, max_depth=10, max_features=None, min_samples_leaf=4, min_samples_split=10, n_estimators=2000;, score=0.889 total time= 9.0min\n",
      "[CV 2/5] END bootstrap=False, criterion=entropy, max_depth=10, max_features=None, min_samples_leaf=4, min_samples_split=10, n_estimators=2000;, score=0.882 total time= 9.7min\n",
      "[CV 3/5] END bootstrap=False, criterion=entropy, max_depth=10, max_features=None, min_samples_leaf=4, min_samples_split=10, n_estimators=2000;, score=0.885 total time= 8.8min\n"
     ]
    }
   ],
   "source": [
    "Accuracy_set, models = evaluate_classifiers(classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_set.sort_values(by='Accuracy(Test)').style.background_gradient(cmap= plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(Accuracy_set[0])):\n",
    "    print(\"Accuracy: \", Accuracy_set[2][index], \"Optimal_Params: \", Accuracy_set[\"Optimal_Params\"][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(Accuracy_set['Accuracy(Test)'])):\n",
    "    plot_confusion_matrix(Accuracy_set['Confusion_Matrix(Test)'][index], \"{} Confusion matrix\".format(Accuracy_set['Model'][index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
